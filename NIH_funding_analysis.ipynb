{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys,codecs,csv,pickle,string\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from funding_analysis import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(2004, 'RePORTER_PRJABS_C_FY2004.csv'),\n (2005, 'RePORTER_PRJABS_C_FY2005.csv'),\n (2006, 'RePORTER_PRJABS_C_FY2006.csv'),\n (2007, 'RePORTER_PRJABS_C_FY2007.csv'),\n (2008, 'RePORTER_PRJABS_C_FY2008.csv'),\n (2009, 'RePORTER_PRJABS_C_FY2009.csv'),\n (2010, 'RePORTER_PRJABS_C_FY2010.csv'),\n (2011, 'RePORTER_PRJABS_C_FY2011.csv'),\n (2012, 'RePORTER_PRJABS_C_FY2012.csv'),\n (2013, 'RePORTER_PRJABS_C_FY2013.csv'),\n (2014, 'RePORTER_PRJABS_C_FY2014.csv'),\n (2015, 'RePORTER_PRJABS_C_FY2015.csv'),\n (2016, 'RePORTER_PRJABS_C_FY2016.csv'),\n (2017, 'RePORTER_PRJABS_C_FY2017.csv'),\n (2018, 'RePORTER_PRJABS_C_FY2018.csv'),\n (2019, 'RePORTER_PRJABS_C_FY2019.csv')]\n"
    }
   ],
   "source": [
    "# create a list of the CSV files and the relevant year\n",
    "csv_files = [f for f in os.listdir() if (f.endswith('.csv') and f.find('_PRJABS_')>-1) ]\n",
    "csv_files = [(d,s) for d in range(4000) for s in csv_files if s.endswith('FY'+str(d)+'.csv') ]\n",
    "pprint(csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found  12  processors.\n"
    }
   ],
   "source": [
    "# in parallel, process the CSV files, and save the output in pickle format\n",
    "if __name__ == '__main__':\n",
    "    with multiprocessing.Pool(processes=4) as pool:              # start 4 worker processes\n",
    "        print('Found ' , multiprocessing.cpu_count() , ' processors.')\n",
    "        multiple_results = [pool.apply_async(TestProcess, (i,)) for i in range(4)]\n",
    "        print([res.get(timeout=110) for res in multiple_results])\n",
    "        #print(pool.map(TestProcess,[csv_files[I][1],csv_files[I][0]]))\n",
    "        #for I in range(len(csv_files)):\n",
    "        #    pool.apply_async(TestProcess, [csv_files[I][1],csv_files[I][0]])\n",
    "        #   result = pool.apply_async(ProcessesWordsInAbstractFile, [csv_files[I][1],csv_files[I][0]])\n",
    "        #pool.close()\n",
    "        #print('all proceses started')\n",
    "        #pool.join()\n",
    "        #print(' -- all finished --')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickle files\n",
    "abstracts = list()\n",
    "years = list()\n",
    "for I in range(len(csv_files)):\n",
    "    (year,abstract_text_list_of_sets) = decompress_pickle(csv_files[I][1].replace('.csv',''))\n",
    "    abstracts.append(abstract_text_list_of_sets)\n",
    "    years.append(year)\n",
    "    print('Finished processing ', year)\n",
    "abstracts = np.array(abstracts)\n",
    "years = np.array(years)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(abstracts[years==year][0]))\n",
    "print(len(abstracts[years==year] ))\n",
    "print(list(abstracts[1][1])[:25])  # first 100 words in one abstract in one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'# of abstracts = {len(abstract_text_list)}')\n",
    "print(\"0: \", abstract_text_list[0])\n",
    "print(\"1: \", abstract_text_list[1])\n",
    "s,m,l = CountGrantsInOneYearWithWord( abstract_text_list, 'yeast')\n",
    "print(f'N={s}\\t%={m}\\ttotal N={l}')\n",
    "\n",
    "#s,m,l = CountGrantsInOneYearWithWord( abstracts[years==2010] , 'yeast')\n",
    "#print(s,m,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_years = sorted(set(years))\n",
    "keywords = ['yeast','cancer','zebrafish','elegans','crispr']\n",
    "for keyword in keywords:\n",
    "    for year in unique_years:\n",
    "        s,m,l = CountGrantsInOneYearWithWord( abstracts[years==year][0] , keyword)\n",
    "        print(year,keyword,m,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the two lists\n",
    "\n",
    "with open('abstracts.pickle', 'wb') as f:\n",
    "    pickle.dump(abstracts, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('years.pickle', 'wb') as f:\n",
    "    pickle.dump(years, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('abstracts.pickle', 'rb') as f:\n",
    "    abstracts = pickle.load(f) \n",
    "\n",
    "with open('years.pickle', 'rb') as f:\n",
    "    years = pickle.load(f)     \n",
    "\n",
    "print(abstracts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}