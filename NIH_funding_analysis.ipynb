{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys,codecs,csv,pickle,string\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from stop_words import get_stop_words\n",
    "import multiprocessing\n",
    "\n",
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2002, 'RePORTER_PRJABS_C_FY2002.csv'),\n",
      " (2006, 'RePORTER_PRJABS_C_FY2006.csv'),\n",
      " (2017, 'RePORTER_PRJABS_C_FY2017.csv'),\n",
      " (2018, 'RePORTER_PRJABS_C_FY2018.csv'),\n",
      " (2019, 'RePORTER_PRJABS_C_FY2019.csv')]\n"
     ]
    }
   ],
   "source": [
    "# create a list of the CSV files and the relevant year\n",
    "#csv_files = [f for f in os.listdir() if f.endswith('.csv') ]\n",
    "#csv_files = [(d,s) for d in range(4000) for s in csv_files if s.endswith('FY'+str(d)+'.csv') ]\n",
    "\n",
    "# only abstract files\n",
    "csv_files = [f for f in os.listdir() if (f.endswith('.csv') and f.find('_PRJABS_')>-1) ]\n",
    "csv_files = [(d,s) for d in range(4000) for s in csv_files if s.endswith('FY'+str(d)+'.csv') ]\n",
    "pprint(csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load compressed pickle files\n",
    "def decompress_pickle(filename):\n",
    "    if os.path.isfile(filename):\n",
    "        data = bz2.BZ2File(filename, 'rb')\n",
    "    elif os.path.isfile( filename + '.pbz2' ):\n",
    "        data = bz2.BZ2File(filename + '.pbz2'  , 'rb')\n",
    "    else:\n",
    "        print('cannot find ', filename)\n",
    "        raise TypeError(\"Only integers are allowed\")\n",
    "    data = cPickle.load(data)\n",
    "    return data\n",
    "\n",
    "def compressed_pickle(filename, data):\n",
    "    with bz2.BZ2File(filename + '.pbz2','w') as f: \n",
    "        cPickle.dump(data, f)\n",
    "\n",
    "\n",
    "# grants_abs_list is a list of sets. each set contains all the words in one grant abstract\n",
    "#   identify the sets in which the word appears\n",
    "#   and return the #, avg, and total # of grants (# of sets)\n",
    "def CountGrantsInOneYearWithWord( grants_abs_list , word):\n",
    "    binary_vect = [word in words for words in grants_abs_list]\n",
    "    return( sum(binary_vect), sum(binary_vect)/len(binary_vect)*100, len(binary_vect) )\n",
    "\n",
    "\n",
    "# load an abstracts CSV file and return a set of unique, no-stop & no-punctuation words\n",
    "#   also save the output as a pickle file\n",
    "def ProcessesWordsInAbstractFile(abstract_csv_file,year):\n",
    "    abstract_text = list()\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    with codecs.open( abstract_csv_file , 'r' , encoding='utf-8', errors='ignore') as csvfile:\n",
    "        csvr = csv.reader(csvfile,delimiter=',')\n",
    "        for app_id, app_txt in csvr:\n",
    "            app_txt = [s.translate(table) for s in app_txt.lower().split(' ')]\n",
    "            filtered_words = [word for word in app_txt  if \\\n",
    "                              ( (word not in get_stop_words('english')) and (len(word)>4) )]\n",
    "            abstract_text.append(set(filtered_words))\n",
    "    compressed_pickle(abstract_csv_file.replace('.csv',''), (year,abstract_text))\n",
    "    return( abstract_text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "closed\n",
      "joined\n"
     ]
    }
   ],
   "source": [
    "# in parallel, process the CSV files, and save the output in pickle format\n",
    "if __name__ == '__main__':\n",
    "    pool = multiprocessing.Pool(processes=6)              # start 4 worker processes\n",
    "    for I in range(len(csv_files)):\n",
    "        result = pool.apply_async(ProcessesWordsInAbstractFile, [csv_files[I][1],csv_files[I][0]])    # evaluate \"f(10)\" asynchronously\n",
    "    pool.close()\n",
    "    print('all proceses started')\n",
    "    pool.join()\n",
    "    print(' -- all finished --')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing  2002\n",
      "Finished processing  2006\n",
      "Finished processing  2017\n",
      "Finished processing  2018\n",
      "Finished processing  2019\n",
      "[2002 2006 2017 2018 2019]\n"
     ]
    }
   ],
   "source": [
    "# load the pickle files\n",
    "abstracts = list()\n",
    "years = list()\n",
    "for I in range(len(csv_files)):\n",
    "    (year,abstract_text_list_of_sets) = decompress_pickle(csv_files[I][1].replace('.csv',''))\n",
    "    abstracts.append(abstract_text_list_of_sets)\n",
    "    years.append(year)\n",
    "    print('Finished processing ', year)\n",
    "abstracts = np.array(abstracts)\n",
    "years = np.array(years)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78916\n",
      "1\n",
      "['whether', 'necessary', 'intracranial', 'patients', 'determine', 'allows', 'comparison', 'present', 'elevated', 'skull', 'built', 'neurosurgeon', 'collect', 'purpose', 'preprototype', 'serious', 'successful', 'improved', 'preliminary', 'measuring', 'analysis', 'implementation', 'measured', 'arterial', 'favorably']\n"
     ]
    }
   ],
   "source": [
    "print(len(abstracts[years==year][0]))\n",
    "print(len(abstracts[years==year] ))\n",
    "print(list(abstracts[1][1])[:25])  # first 100 words in one abstract in one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'# of abstracts = {len(abstract_text_list)}')\n",
    "print(\"0: \", abstract_text_list[0])\n",
    "print(\"1: \", abstract_text_list[1])\n",
    "s,m,l = CountGrantsInOneYearWithWord( abstract_text_list, 'yeast')\n",
    "print(f'N={s}\\t%={m}\\ttotal N={l}')\n",
    "\n",
    "#s,m,l = CountGrantsInOneYearWithWord( abstracts[years==2010] , 'yeast')\n",
    "#print(s,m,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\tyeast\t2.907286439204912\n",
      "2006\tyeast\t2.5473700762638574\n",
      "2017\tyeast\t1.260007152879034\n",
      "2018\tyeast\t1.2288040636438335\n",
      "2019\tyeast\t1.174666734249075\n",
      "2002\tcancer\t13.328100030839105\n",
      "2006\tcancer\t15.38642975076657\n",
      "2017\tcancer\t19.37054664502462\n",
      "2018\tcancer\t23.03727496825278\n",
      "2019\tcancer\t20.012418267524964\n",
      "2002\tzebrafish\t0.407917239059127\n",
      "2006\tzebrafish\t0.6494221243808476\n",
      "2017\tzebrafish\t1.0069052793749484\n",
      "2018\tzebrafish\t0.9710913572869202\n",
      "2019\tzebrafish\t0.9643164884180648\n",
      "2002\telegans\t0.5943536404160475\n",
      "2006\telegans\t0.7453416149068323\n",
      "2017\telegans\t0.7991966766623566\n",
      "2018\telegans\t0.7681581633923458\n",
      "2019\telegans\t0.7210198185412338\n",
      "2002\tcrispr\t0.0\n",
      "2006\tcrispr\t0.0015724506643604059\n",
      "2017\tcrispr\t0.550221464139316\n",
      "2018\tcrispr\t0.689723861457633\n",
      "2019\tcrispr\t0.8920877895483805\n"
     ]
    }
   ],
   "source": [
    "unique_years = sorted(set(years))\n",
    "keywords = ['yeast','cancer','zebrafish','elegans','crispr']\n",
    "for keyword in keywords:\n",
    "    for year in unique_years:\n",
    "        s,m,l = CountGrantsInOneYearWithWord( abstracts[years==year][0] , keyword)\n",
    "        print(year,keyword,m,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the two lists\n",
    "\n",
    "with open('abstracts.pickle', 'wb') as f:\n",
    "    pickle.dump(abstracts, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('years.pickle', 'wb') as f:\n",
    "    pickle.dump(years, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('abstracts.pickle', 'rb') as f:\n",
    "    abstracts = pickle.load(f) \n",
    "\n",
    "with open('years.pickle', 'rb') as f:\n",
    "    years = pickle.load(f)     \n",
    "\n",
    "print(abstracts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
