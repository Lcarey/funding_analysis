{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os,sys,codecs,csv,pickle,string\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from stop_words import get_stop_words\n",
    "import multiprocessing, datetime\n",
    "\n",
    "import bz2\n",
    "import pickle\n",
    "import _pickle as cPickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(2004, 'RePORTER_PRJABS_C_FY2004.csv'),\n (2005, 'RePORTER_PRJABS_C_FY2005.csv'),\n (2006, 'RePORTER_PRJABS_C_FY2006.csv'),\n (2007, 'RePORTER_PRJABS_C_FY2007.csv'),\n (2008, 'RePORTER_PRJABS_C_FY2008.csv'),\n (2009, 'RePORTER_PRJABS_C_FY2009.csv'),\n (2010, 'RePORTER_PRJABS_C_FY2010.csv'),\n (2011, 'RePORTER_PRJABS_C_FY2011.csv'),\n (2012, 'RePORTER_PRJABS_C_FY2012.csv'),\n (2013, 'RePORTER_PRJABS_C_FY2013.csv'),\n (2014, 'RePORTER_PRJABS_C_FY2014.csv'),\n (2015, 'RePORTER_PRJABS_C_FY2015.csv'),\n (2016, 'RePORTER_PRJABS_C_FY2016.csv'),\n (2017, 'RePORTER_PRJABS_C_FY2017.csv'),\n (2018, 'RePORTER_PRJABS_C_FY2018.csv'),\n (2019, 'RePORTER_PRJABS_C_FY2019.csv')]\n"
    }
   ],
   "source": [
    "# create a list of the CSV files and the relevant year\n",
    "#csv_files = [f for f in os.listdir() if f.endswith('.csv') ]\n",
    "#csv_files = [(d,s) for d in range(4000) for s in csv_files if s.endswith('FY'+str(d)+'.csv') ]\n",
    "\n",
    "# only abstract files\n",
    "csv_files = [f for f in os.listdir() if (f.endswith('.csv') and f.find('_PRJABS_')>-1) ]\n",
    "csv_files = [(d,s) for d in range(4000) for s in csv_files if s.endswith('FY'+str(d)+'.csv') ]\n",
    "pprint(csv_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load compressed pickle files\n",
    "def decompress_pickle(filename):\n",
    "    if os.path.isfile(filename):\n",
    "        data = bz2.BZ2File(filename, 'rb')\n",
    "    elif os.path.isfile( filename + '.pbz2' ):\n",
    "        data = bz2.BZ2File(filename + '.pbz2'  , 'rb')\n",
    "    else:\n",
    "        print('cannot find ', filename)\n",
    "        raise TypeError(\"Only integers are allowed\")\n",
    "    data = cPickle.load(data)\n",
    "    return data\n",
    "\n",
    "def compressed_pickle(filename, data):\n",
    "    with bz2.BZ2File(filename + '.pbz2','w') as f: \n",
    "        cPickle.dump(data, f)\n",
    "\n",
    "\n",
    "# grants_abs_list is a list of sets. each set contains all the words in one grant abstract\n",
    "#   identify the sets in which the word appears\n",
    "#   and return the #, avg, and total # of grants (# of sets)\n",
    "def CountGrantsInOneYearWithWord( grants_abs_list , word):\n",
    "    binary_vect = [word in words for words in grants_abs_list]\n",
    "    return( sum(binary_vect), sum(binary_vect)/len(binary_vect)*100, len(binary_vect) )\n",
    "\n",
    "\n",
    "# load an abstracts CSV file and return a set of unique, no-stop & no-punctuation words\n",
    "#   also save the output as a pickle file\n",
    "def ProcessesWordsInAbstractFile(abstract_csv_file,year):\n",
    "    abstract_text = list()\n",
    "    table = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    with codecs.open( abstract_csv_file , 'r' , encoding='utf-8', errors='ignore') as csvfile:\n",
    "        csvr = csv.reader(csvfile,delimiter=',')\n",
    "        print('Starting with ', abstract_csv_file, ' saving to disk: ', datetime.datetime.now() )\n",
    "        for app_id, app_txt in csvr:\n",
    "            app_txt = [s.translate(table) for s in app_txt.lower().split(' ')]\n",
    "            filtered_words = [word for word in app_txt  if \\\n",
    "                              ( (word not in get_stop_words('english')) and (len(word)>4) )]\n",
    "            abstract_text.append(set(filtered_words))\n",
    "    print('Finished with ', abstract_csv_file, ' saving to disk: ', datetime.datetime.now() )\n",
    "    compressed_pickle(abstract_csv_file.replace('.csv',''), (year,abstract_text))\n",
    "    return( abstract_text )\n",
    "\n",
    "def TestProcess(x):\n",
    "    #return(arg1)\n",
    "    #print('Running TestProcess: ', arg1, arg2)\n",
    "    #print('current_process: ', multiprocessing.current_process())\n",
    "    #print('parent_process: ', multiprocessing.parent_process())\n",
    "    return(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found  12  processors.\n"
    },
    {
     "output_type": "error",
     "ename": "TimeoutError",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-c2df0bdcd905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found '\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m' processors.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmultiple_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestProcess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmultiple_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(pool.map(TestProcess,[csv_files[I][1],csv_files[I][0]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#for I in range(len(csv_files)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-31-c2df0bdcd905>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Found '\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m' processors.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmultiple_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTestProcess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmultiple_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m#print(pool.map(TestProcess,[csv_files[I][1],csv_files[I][0]]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#for I in range(len(csv_files)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python@3.8/3.8.3_2/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_success\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# in parallel, process the CSV files, and save the output in pickle format\n",
    "if __name__ == '__main__':\n",
    "    with multiprocessing.Pool(processes=4) as pool:              # start 4 worker processes\n",
    "        print('Found ' , multiprocessing.cpu_count() , ' processors.')\n",
    "        multiple_results = [pool.apply_async(TestProcess, (i)) for i in range(4)]\n",
    "        print([res.get(timeout=1) for res in multiple_results])\n",
    "        #print(pool.map(TestProcess,[csv_files[I][1],csv_files[I][0]]))\n",
    "        #for I in range(len(csv_files)):\n",
    "        #    pool.apply_async(TestProcess, [csv_files[I][1],csv_files[I][0]])\n",
    "        #   result = pool.apply_async(ProcessesWordsInAbstractFile, [csv_files[I][1],csv_files[I][0]])\n",
    "        #pool.close()\n",
    "        #print('all proceses started')\n",
    "        #pool.join()\n",
    "        #print(' -- all finished --')\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pickle files\n",
    "abstracts = list()\n",
    "years = list()\n",
    "for I in range(len(csv_files)):\n",
    "    (year,abstract_text_list_of_sets) = decompress_pickle(csv_files[I][1].replace('.csv',''))\n",
    "    abstracts.append(abstract_text_list_of_sets)\n",
    "    years.append(year)\n",
    "    print('Finished processing ', year)\n",
    "abstracts = np.array(abstracts)\n",
    "years = np.array(years)\n",
    "print(years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(abstracts[years==year][0]))\n",
    "print(len(abstracts[years==year] ))\n",
    "print(list(abstracts[1][1])[:25])  # first 100 words in one abstract in one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( f'# of abstracts = {len(abstract_text_list)}')\n",
    "print(\"0: \", abstract_text_list[0])\n",
    "print(\"1: \", abstract_text_list[1])\n",
    "s,m,l = CountGrantsInOneYearWithWord( abstract_text_list, 'yeast')\n",
    "print(f'N={s}\\t%={m}\\ttotal N={l}')\n",
    "\n",
    "#s,m,l = CountGrantsInOneYearWithWord( abstracts[years==2010] , 'yeast')\n",
    "#print(s,m,l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_years = sorted(set(years))\n",
    "keywords = ['yeast','cancer','zebrafish','elegans','crispr']\n",
    "for keyword in keywords:\n",
    "    for year in unique_years:\n",
    "        s,m,l = CountGrantsInOneYearWithWord( abstracts[years==year][0] , keyword)\n",
    "        print(year,keyword,m,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the two lists\n",
    "\n",
    "with open('abstracts.pickle', 'wb') as f:\n",
    "    pickle.dump(abstracts, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open('years.pickle', 'wb') as f:\n",
    "    pickle.dump(years, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('abstracts.pickle', 'rb') as f:\n",
    "    abstracts = pickle.load(f) \n",
    "\n",
    "with open('years.pickle', 'rb') as f:\n",
    "    years = pickle.load(f)     \n",
    "\n",
    "print(abstracts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}